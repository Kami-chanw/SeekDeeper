{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules and Data\n",
    "We use a subset of [Children's Book Test(CST)](https://arxiv.org/pdf/1511.02301) dataset to evaluate the zero-shot ability of GPT-2. You can learn more and download from [cam-cst/cbt](https://huggingface.co/datasets/cam-cst/cbt).\n",
    "\n",
    "As original paper reported, GPT-2 obtained accuracy of 87.65 which outperformed SoTA at the time. We are going to reproduce this result in this notebook.\n",
    "\n",
    "The data retrieved from data loader has been tokenized and converted to indices corresponding to the vocab. Since cam-cst/cbt ensures that each row in \"options\" column contains 10 options, sentences will be shaped in `[batch_size, 10, seq_len]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "\n",
    "tokenizer, test_dataloader = load_data(\"cbt\", config_name=\"CN\", splits=[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, max_len=1024\n",
      "number of parameters: 123.65M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import config\n",
    "from modules import GPT2\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model = GPT2.from_pretrained(str(config.pretrained_dir)).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Ability\n",
    "You can compare the generate ability with [GPT](https://github.com/Kami-chanw/SeekDeeper/blob/main/gpt/inference.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, I'm Kami-chanw, a writer for Kamen Rider Gaiden 2 and Kadokawa, and this review of Victory Victory several\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi, I'm Kami-chanw, a\"\n",
    "ids = tokenizer.encode(text)\n",
    "ids_tensor = torch.tensor(ids, dtype=torch.long)\n",
    "tokenizer.decode(\n",
    "    model.generate(ids_tensor.to(device), max_new_tokens=20).tolist(),\n",
    "    skip_special_tokens=True,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test on CST\n",
    "Unlike GPT-1, GPT-2 can be tested on the CBT dataset without any fine-tuning.\n",
    "\n",
    "The Sec 3.2 in original paper introduced how to test on CBT:\n",
    "\n",
    "> Following the LM approach introduced in the original paper, we compute the\n",
    "probability of each choice and the rest of the sentence conditioned on this choice according to the LM, and predict\n",
    "the one with the highest probability.\n",
    "\n",
    "We end up with an accuracy of 86.84, which is close to the 87.65 reported in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0028fae4483f4b858232d1300900ee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.8400\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import pad_idx\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for texts, answer_idx in tqdm(test_dataloader, desc=\"Testing: \"):\n",
    "    texts, answer_idx = texts.to(device), answer_idx.to(device)\n",
    "    texts = texts[:, :, -config.max_len :]\n",
    "    batch_size, num_options, seq_len = texts.shape\n",
    "    labels = texts.masked_fill(texts == pad_idx, -100)\n",
    "    with torch.no_grad():\n",
    "        # [batch_size * num_options, seq_len]\n",
    "        lm_logits = model(texts.view(-1, seq_len), (texts != pad_idx).view(-1, seq_len))\n",
    "        shift_logits = lm_logits[..., :-1, :]\n",
    "        shift_labels = labels[..., 1:]\n",
    "        loss = F.cross_entropy(\n",
    "            shift_logits.reshape(-1, shift_logits.size(-1)),\n",
    "            shift_labels.reshape(-1),\n",
    "            reduction=\"none\",\n",
    "        )\n",
    "        loss_per_option = loss.view(batch_size, num_options, -1).sum(dim=-1)\n",
    "        max_idx = torch.argmin(loss_per_option, dim=1)\n",
    "\n",
    "    all_preds.extend(max_idx.cpu().numpy())\n",
    "    all_labels.extend(answer_idx.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy * 100:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
