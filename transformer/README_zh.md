[$$ğŸ“–English ReadMe\]](./README.md)
## Introduction
åœ¨è¿™é‡Œï¼Œæˆ‘å®ç°äº†ä¸€ä¸ªTransformerï¼Œå¹¶ä½¿ç”¨å…¶åœ¨Multi30kæ•°æ®é›†ä¸Šè¿›è¡Œäº†è‹±-å¾·ç¿»è¯‘ä»»åŠ¡ï¼ˆè§[æ­¤](./train.ipynb)ï¼‰ã€‚åœ¨è®­ç»ƒæ¨¡å‹ä¹‹åï¼Œä½ å¯ä»¥åœ¨[æ­¤](./inference.ipynb)åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†ã€‚

## Model details
### [Transformer](./modules/transformer.py)
Transformeræœ€åˆæå‡ºè¢«ç”¨äºè§£å†³ç¿»è¯‘ä»»åŠ¡ã€‚å¦‚æœè¦å®ç°ä¸­æ–‡åˆ°è‹±æ–‡çš„ç¿»è¯‘ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç§°ä¸­æ–‡ä¸ºæºè¯­è¨€ï¼Œè‹±æ–‡ä¸ºç›®æ ‡è¯­è¨€ã€‚Transformerçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæºæ–‡æœ¬çš„embeddingä¸positional encodingç›¸åŠ åè¾“å…¥åˆ°Encoderï¼Œç»è¿‡Nå±‚Encoder layeråï¼Œè¾“å‡ºåœ¨Decoderçš„cross attentionä¸­è¿›è¡Œäº¤äº’ã€‚ç›®æ ‡æ–‡æœ¬çš„embeddingåŒæ ·ä¸positional encodingç›¸åŠ åè¾“å…¥åˆ°Decoderï¼ŒDncoderçš„è¾“å‡ºé€šå¸¸ä¼šå†ç»è¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆå…·ä½“å–å†³äºä»»åŠ¡è¦æ±‚ï¼‰ã€‚
<div style="text-align: center;">
  <img src="./images/transformer.png" alt="Transformer" style="width: 300px; height: auto;">
</div>

Encoderå’ŒDecoderåˆ†åˆ«ä½¿ç”¨äº†ä¸¤ç§maskï¼Œ`src_mask`å’Œ`tgt_mask`ã€‚`src_mask`ç”¨äºé®ç›–æ‰€æœ‰çš„PAD tokenï¼Œé¿å…å®ƒä»¬åœ¨attentionè®¡ç®—ä¸­äº§ç”Ÿå½±å“ã€‚`tgt_mask`é™¤äº†é®ç›–æ‰€æœ‰PAD tokenï¼Œè¿˜è¦é˜²æ­¢æ¨¡å‹åœ¨è¿›è¡Œnext word predictionæ—¶è®¿é—®æœªæ¥çš„è¯ã€‚

### [Positional Encoding](./modules/layers.py)
ç”±äºTransformerä¸åƒRNNé‚£æ ·å…·æœ‰å¤©ç„¶çš„åºåˆ—ç‰¹æ€§ï¼Œåœ¨è®¡ç®—attentionæ—¶ä¼šä¸¢å¤±é¡ºåºä¿¡æ¯ï¼Œå› æ­¤éœ€è¦å¼•å…¥ä½ç½®ç¼–ç ã€‚åœ¨åŸå§‹è®ºæ–‡ä¸­ï¼Œä½ç½®ç¼–ç çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

- å¯¹äºå¶æ•°ç»´åº¦ï¼š
  $$
   \text{PE}(pos, 2i) = \sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)
  $$

- å¯¹äºå¥‡æ•°ç»´åº¦ï¼š
  $$ 
  \text{PE}(pos, 2i+1) = \cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right) 
  $$

ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¯¹div termå–æŒ‡æ•°å’Œå¯¹æ•°ï¼Œå³ï¼š
$$
\text{div\_ term} = 10000^{2i/d_{\text{model}}} = \exp\left(\frac{2i \cdot -\log(10000)}{d_{\text{model}}}\right)
$$

ä½ç½®ç¼–ç å¯¹ä»»ä½•åºåˆ—éƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤positional encodingçš„shapeä¸º`[seq_len, d_model]`ã€‚ç„¶åæ ¹æ®å¹¿æ’­æœºåˆ¶ä¸shapeä¸º`[batch_size, seq_len, d_model]`çš„input embeddingç›¸åŠ ï¼Œå¾—åˆ°Encoderçš„è¾“å…¥ï¼Œè®°ä½œ$x_0$ã€‚

## [Encoder](./modules/encoder.py)
EncoderåŒ…å«å¤šä¸ªç›¸åŒçš„å±‚ã€‚ä¸Šä¸€å±‚çš„è¾“å‡º$x_i$ä»¥å¦‚ä¸‹é€”å¾„ç»è¿‡è¯¥å±‚ï¼ˆçœç•¥äº†dropoutï¼‰ï¼š
```python
# attention mechanism
residual = x
x = multihead_attention(q=x, k=x, v=x, mask=src_mask)
x = layer_norm(x + residual)

# position-wise feed forward
residual = x
x = feed_forward(x)
x = layer_norm(x + residual)
```

## [Attention](./modules/layers.py)
Attentionçš„è®¡ç®—æµç¨‹å¦‚ä¸‹ï¼š
<div style="text-align: center;">
  <img src="./images/attention.png" alt="Attention" style="width: 400px; height: auto;">
</div>
åœ¨Encoderçš„self-attentionä¸­ï¼ŒKã€Qã€Vå‡ä¸ºä¸Šä¸€å±‚çš„è¾“å‡ºç»è¿‡ä¸åŒçº¿æ€§å±‚å¾—åˆ°çš„ã€‚åœ¨Decoderçš„cross-attentionä¸­ï¼ŒKå’ŒVæ¥è‡ªEncoderæœ€åä¸€å±‚çš„è¾“å‡ºï¼Œè€ŒQæ˜¯Decoderä¸Šä¸€å±‚çš„è¾“å‡ºã€‚

ä¸ºäº†ä½¿æ¨¡å‹å…³æ³¨ä¸åŒä½ç½®çš„ä¸åŒç‰¹å¾å­ç©ºé—´ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œå°†shapeä¸º`[batch_size, seq_len, d_model]`çš„Kã€Qã€Våˆ†ä¸º`[batch_size, seq_len, n_head, d_key]`ï¼Œå†äº¤æ¢`seq_len`å’Œ`n_head`ä¸¤ä¸ªç»´åº¦ï¼Œä»¥ä¾¿è¿›è¡Œattentionæœºåˆ¶ä¸­çš„çŸ©é˜µä¹˜æ³•ã€‚è®¡ç®—äº†attentionä¹‹åå†å°†ç»“æœåˆå¹¶ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚æ˜ å°„åˆ°ä¸è¾“å…¥ç›¸åŒçš„ç»´åº¦ã€‚ç®—æ³•çš„æµç¨‹å¦‚ä¸‹ï¼š
```python
# projection
K, Q, V = W_k(x), W_q(x), W_v(x)

# split
d_key = d_model // n_head
K, Q, V = (K, Q, V).view(batch_size, seq_len, n_head, d_key).transpose(1, 2)
out = scaled_dot_product_attention(K, Q, V)

#concatenate
out = out.transpose(1, 2).view(batch_size, seq_len, d_model)
out = W_cat(out)
```

Scaled Dot-Product Attentionç”¨å…¬å¼è¡¨ç¤ºä¸ºï¼š
$$
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_{key}}}\right) \cdot V
$$

## [Decoder](./modules/decoder.py)
Decoderç›¸è¾ƒäºEncoderé™¤äº†å¤šäº†ä¸€å±‚cross-attentionä¹‹å¤–ï¼Œè¿˜ä½¿ç”¨äº†masked multi-head attentionã€‚ç”±äºæ¨¡å‹åœ¨æ­¤å¤„ä¸èƒ½è®¿é—®æœªæ¥ä¿¡æ¯ï¼Œå› æ­¤è¿™ç§æ³¨æ„åŠ›æœºåˆ¶ä¹Ÿç§°ä¸ºcausal self-attentionã€‚
DecoderåŒæ ·åŒ…å«å¤šä¸ªç›¸åŒçš„å±‚ï¼ŒEncoderæœ€åä¸€å±‚çš„è¾“å‡º`enc`å’ŒDecoderä¸Šä¸€å±‚çš„è¾“å‡º`dec`ä»¥å¦‚ä¸‹é€”å¾„ç»è¿‡è¯¥å±‚ï¼ˆçœç•¥äº†dropoutï¼‰ï¼š
```python
# causal self-attention
residual = dec
x = multihead_attention(q=dec, k=dec, v=dec, mask=tgt_mask)
x = layer_norm(x + residual)

# cross-attention
x = multihead_attention(q=x, k=enc, v=enc, mask=tgt_mask)
x = layer_norm(x + residual)

# position-wise feed forward
residual = x
x = feed_forward(x)
x = layer_norm(x + residual)
```

## Training Strategy
### Training Data and Batching
[Attention is all you need](https://arxiv.org/pdf/1706.03762) Sec 5.1 æåˆ°ï¼Œè®­ç»ƒé›†ä½¿ç”¨çš„æ˜¯WMT 2014ï¼Œæ¯ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡æœ‰å¤§çº¦25k source tokenså’Œ25k target tokensï¼Œç»“æœäº§ç”Ÿäº† 6,230 ä¸ªæ‰¹æ¬¡ã€‚å¹³å‡æ‰¹æ¬¡å¤§å°ä¸º 724ï¼Œå¹³å‡é•¿åº¦ä¸º 45 ä¸ªtokensã€‚è€ƒè™‘åˆ°GPUæ˜¾å­˜ä¸è¶³ï¼Œä¸ºäº†ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡éƒ½è¶³å¤Ÿçš„tokensï¼Œå› æ­¤éœ€è¦é‡‡å–æ¢¯åº¦ç´¯ç§¯ç­–ç•¥ï¼Œæ¯`update_freq`è½®æ‰æ›´æ–°ä¸€æ¬¡æ¢¯åº¦ã€‚

è®ºæ–‡è¿˜æåˆ°å¯¹base transformerè¿›è¡Œäº† 100,000 æ¬¡è¿­ä»£è®­ç»ƒï¼Œè¿™åº”è¯¥å¯¹åº”äº 16 ä¸ªepochsã€‚
### Optimizer
[Attention is all you need](https://arxiv.org/pdf/1706.03762) Sec 5.3 æåˆ°ï¼Œä¼˜åŒ–å™¨ä½¿ç”¨çš„æ˜¯ Adamï¼Œå‚æ•°ä¾æ¬¡ä¸º$\beta_1 = 0.9, \beta_2 = 0.98, \epsilon = 10^{-9}$ã€‚æ­¤å¤–ï¼Œæ ¹æ®å¦‚ä¸‹å…¬å¼ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¹å˜äº†å­¦ä¹ ç‡ï¼š

$$lrate=d_{\mathrm{model}}^{-0.5}\cdot\min(step\_ num^{-0.5},step\_ num\cdot warmup\_ steps^{-1.5})$$

è¿™ç›¸å½“äºåœ¨å‰ $warmup_steps$ è®­ç»ƒæ­¥éª¤ä¸­çº¿æ€§å¢åŠ å­¦ä¹ ç‡ï¼Œç„¶åæŒ‰æ­¥æ•°çš„å¹³æ–¹æ ¹å€’æ•°æ¯”ä¾‹é™ä½å­¦ä¹ ç‡ã€‚Transformer base è®­ç»ƒäº† 100,000 æ­¥ï¼Œåœ¨æ­¤è®¾ç½®ä¸‹ $warmup\_ steps = 4000$ã€‚

### Label Smoothing
[Attention is all you need](https://arxiv.org/pdf/1706.03762) Sec 5.4 æåˆ°ä½¿ç”¨æ ‡ç­¾å¹³æ»‘æŠ€æœ¯è™½ç„¶ä¼šæŸå®³æ¨¡å‹çš„å›°æƒ‘åº¦ï¼Œä½†å¯ä»¥ç•¥å¾®æå‡BLEUå’Œå‡†ç¡®ç‡ã€‚æ ‡ç­¾å¹³æ»‘æ˜¯[Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/pdf/1512.00567)ä¸­æå‡ºçš„ã€‚å®ƒæ˜¯ä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®¡ç®—æŸå¤±æ—¶å¯¹ç›®æ ‡æ ‡ç­¾è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œä»è€Œé˜²æ­¢æ¨¡å‹è¿‡åº¦è‡ªä¿¡åœ°é¢„æµ‹å•ä¸ªç±»åˆ«ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒå°†æ ‡ç­¾ä»ç¡¬æ ‡ç­¾ï¼ˆone-hot vectorï¼‰è½¬å˜ä¸ºè½¯æ ‡ç­¾ï¼ˆsoft labelsï¼‰ï¼Œä»è€Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥ä¸€äº›ä¸ç¡®å®šæ€§ã€‚

å‡è®¾æœ‰ä¸€ä¸ªç±»åˆ«æ•°ä¸º $C$ çš„åˆ†ç±»ä»»åŠ¡ï¼Œå¯¹äºæ¯ä¸ªæ ·æœ¬ $x$ï¼Œæ ‡ç­¾å¹³æ»‘åçš„ç›®æ ‡åˆ†å¸ƒ $y_{\text{smooth}}$ å®šä¹‰ä¸ºï¼š

$$y_{\text{smooth}} = (1 - \epsilon) \cdot y_{\text{one-hot}} + (1-y_{\text{one-hot}})\cdot \frac{\epsilon}{C-1}$$

å…¶ä¸­ï¼Œ$\epsilon$ æ˜¯å¹³æ»‘å‚æ•°ï¼Œé»˜è®¤ä¸º 0.1ã€‚$y_{\text{one-hot}}$ æ˜¯åŸå§‹çš„one-hotæ ‡ç­¾ã€‚

ä½ å¯ä»¥åœ¨[config.py](./config.py)ä¸­ä¿®æ”¹`eps_ls`æ§åˆ¶$\epsilon$çš„å¤§å°ã€‚å¦‚æœ$\epsilon=0$åˆ™å°†ç¦ç”¨æ ‡ç­¾å¹³æ»‘ï¼Œä½¿ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ã€‚

## Evaluation
ä¸ºäº†è¯„ä¼°æœºå™¨ç¿»è¯‘çš„æ•ˆæœï¼Œæœ¬å®ç°éµå¾ªäº†[Attention is all you need](https://arxiv.org/pdf/1706.03762)çš„è®¾ç½®ï¼Œä½¿ç”¨[BLEU](https://aclanthology.org/P02-1040.pdf)åˆ†æ•°ã€‚å…·ä½“è¿‡ç¨‹æ˜¯ï¼Œå…ˆä½¿æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ç»è¿‡transformerçš„å‰å‘è¿‡ç¨‹ï¼Œç„¶åä½¿ç”¨greedy decodeçš„æ–¹æ³•ä»decoderè¾“å‡ºä¸­é€‰å–æ¦‚ç‡æœ€å¤§çš„tokenä½œä¸ºé¢„æµ‹ç»“æœã€‚ç„¶ååˆ©ç”¨[sacrebleu](https://github.com/mjpost/sacrebleu)è®¡ç®—BLEUã€‚

ä¸ºäº†æé«˜ç¿»è¯‘çš„æ•ˆæœï¼Œå®é™…ä¸Šä¹Ÿå¯ä»¥ä½¿ç”¨beam searchä½œä¸ºdecodeæ–¹æ³•ï¼Œæ¬¢è¿æäº¤PR :)ã€‚

## Inference
åœ¨æ¨ç†æµ‹è¯•é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨åŸè¯­è¨€è¯­å¥é€šè¿‡