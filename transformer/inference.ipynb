{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Modules and Data\n",
                "It contians following steps:\n",
                "1. Use tokenizers from `spacy` to tokenize texts from train test_dataset. \n",
                "2. Build the vocabulary, i.e. the tokens for the index dictionary. A list of special tokens (e.g. `<eos>`, `<pad>`) is prepended to the entire table.\n",
                "3. Prepare test_dataset and dataloader."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "device(type='cuda', index=0)"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from data import load_data\n",
                "from modules import Transformer, make_pad_mask, make_causal_mask\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import random\n",
                "import config\n",
                "import os\n",
                "\n",
                "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
                "\n",
                "src_lang = \"en\"\n",
                "tgt_lang = \"de\"\n",
                "\n",
                "src_vocab, tgt_vocab, train_dataloader, valid_dataloader, test_dataloader = (\n",
                "    load_data(src_lang, tgt_lang)\n",
                ")\n",
                "\n",
                "dataset = test_dataloader.dataset\n",
                "\n",
                "torch.manual_seed(3407)\n",
                "config.device"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = Transformer(\n",
                "    src_pad_idx=src_vocab[\"<pad>\"],\n",
                "    tgt_pad_idx=tgt_vocab[\"<pad>\"],\n",
                "    src_vocab_size=len(src_vocab),\n",
                "    tgt_vocab_size=len(tgt_vocab),\n",
                "    d_model=config.d_model,\n",
                "    n_head=config.n_head,\n",
                "    max_len=config.max_len,\n",
                "    ffn_hidden=config.ffn_hidden,\n",
                "    n_layer=config.n_layer,\n",
                "    dropout=config.dropout,\n",
                "    device=config.device,\n",
                ")\n",
                "state_dict = torch.load(os.path.join(config.checkpoint_dir, \"en_de.pth\"))\n",
                "model.load_state_dict(state_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Inference\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Ein Mann einem einem einem .'"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def greedy_search(model, src_sentence, max_len=50):\n",
                "    model.eval()\n",
                "    src_tokens = (\n",
                "        [src_vocab[\"<sos>\"]]\n",
                "        + [src_vocab.get(word, src_vocab[\"<unk>\"]) for word in src_sentence.split()]\n",
                "        + [src_vocab[\"<eos>\"]]\n",
                "    )\n",
                "    src_tensor = torch.LongTensor(src_tokens).unsqueeze(0).to(config.device)\n",
                "    memory = model.encode(src_tensor)\n",
                "    memory_mask = make_pad_mask(memory, tgt_vocab[\"<pad>\"])\n",
                "    special_index = [\n",
                "        tgt_vocab[\"<sos>\"],\n",
                "        tgt_vocab[\"<pad>\"],\n",
                "        tgt_vocab[\"<unk>\"],\n",
                "        tgt_vocab[\"<eos>\"],\n",
                "    ]\n",
                "\n",
                "    tgt_tokens = [tgt_vocab[\"<sos>\"]]\n",
                "    for _ in range(max_len):\n",
                "        tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(config.device)\n",
                "        output = model.decode(tgt_tensor, memory, memory_mask)\n",
                "        next_token = output.argmax(2)[:, -1].item()\n",
                "        tgt_tokens.append(next_token)\n",
                "        if next_token == tgt_vocab[\"<eos>\"]:\n",
                "            break\n",
                "\n",
                "    return \" \".join(\n",
                "        [\n",
                "            list(tgt_vocab.keys())[list(tgt_vocab.values()).index(token)]\n",
                "            for token in tgt_tokens\n",
                "            if token not in special_index\n",
                "        ]\n",
                "    )\n",
                "\n",
                "\n",
                "greedy_search(model, \"A girl in karate uniform breaking a stick with a front kick.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
