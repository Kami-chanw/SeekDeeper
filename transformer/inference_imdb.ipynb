{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Modules and Data\n",
                "If you haven't download IMDB dataset, please run `download_imdb.py` or download and unzip `aclImdb_v1.tar.gz` from [here](http://ai.stanford.edu/~amaas/data/sentiment)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "device(type='cuda', index=0)"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from data_imdb import test_dataset, tokenizer, vocab, PAD_TOKEN\n",
                "from modules import Encoder,  make_src_mask\n",
                "import torch\n",
                "from torch import nn\n",
                "import config\n",
                "from tqdm import tqdm\n",
                "import random\n",
                "import os\n",
                "\n",
                "torch.manual_seed(3407)\n",
                "config.device"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Build Classifier Model\n",
                "We only need to use the transformer encoder as a text feature extractor, and then use the CLS token attached to the beginning of each text to make predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "SentimentClassifier(\n",
                            "  (encoder): Encoder(\n",
                            "    (emb): TransformerEmbedding(\n",
                            "      (tok_emb): Embedding(89530, 512)\n",
                            "      (pos_emb): PositionalEncoding()\n",
                            "      (drop_out): Dropout(p=0.1, inplace=False)\n",
                            "    )\n",
                            "    (layers): ModuleList(\n",
                            "      (0-5): 6 x EncoderLayer(\n",
                            "        (self_attn): MultiheadAttention(\n",
                            "          (attention): ScaledDotProductAttention(\n",
                            "            (softmax): Softmax(dim=-1)\n",
                            "          )\n",
                            "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
                            "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
                            "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
                            "          (w_concat): Linear(in_features=512, out_features=512, bias=True)\n",
                            "        )\n",
                            "        (ln_1): LayerNorm()\n",
                            "        (dropout): Dropout(p=0.1, inplace=False)\n",
                            "        (ffn): PositionwiseFeedForward(\n",
                            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
                            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
                            "          (relu): ReLU()\n",
                            "          (dropout): Dropout(p=0.1, inplace=False)\n",
                            "        )\n",
                            "        (ln_2): LayerNorm()\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
                            ")"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "class SentimentClassifier(nn.Module):\n",
                "    def __init__(self, encoder, d_model, device):\n",
                "        super(SentimentClassifier, self).__init__()\n",
                "        self.encoder = encoder\n",
                "        self.fc = nn.Linear(d_model, 2, device=device)\n",
                "\n",
                "    def forward(self, input_ids, attention_mask):\n",
                "        encoder_output = self.encoder(input_ids, attention_mask)\n",
                "        cls_token_output = encoder_output[:, 0, :]  # Extract CLS token\n",
                "        logits = self.fc(cls_token_output)\n",
                "        return logits\n",
                "    \n",
                "    \n",
                "model = SentimentClassifier(\n",
                "    Encoder(\n",
                "        enc_voc_size=len(vocab),\n",
                "        max_len=config.max_len,\n",
                "        d_model=config.d_model,\n",
                "        ffn_hidden=config.ffn_hidden,\n",
                "        n_head=config.n_head,\n",
                "        n_layer=config.n_layer,\n",
                "        dropout=config.dropout,\n",
                "        device=config.device,\n",
                "    ),\n",
                "    config.d_model,\n",
                "    device=config.device\n",
                ")\n",
                "\n",
                "model.load_state_dict(torch.load(os.path.join(config.checkpoint_dir, 'imdb_ckpt.pth')))\n",
                "model.eval()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Inference\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Text: <cls> a strange relationship between a middle-aged woman and a transsexual who gonna be a woman <unk> charlotte and <unk> both trapped by their inanimate lives and don't know how to get out of <unk> charlotte is an owner of a beauty <unk> she has broken up with her aggressive <unk> moved into an apartment alone with all the furniture packed except her big <unk> veronica lives downstairs with her poor <unk> <unk> sensitive and desperately bothered by her <unk> visiting and the bad relationship with her <unk> her only hope is that the upcoming transsexual operation will turn her into a real woman and then everything will be <unk> all she can do now is waiting for an approval <unk> <unk> <unk> these two individuals meet by chance and gradually they are all involved into <unk> <unk> there are some sparkles between <unk> but no one is brave enough to face the truth because they are not willing to accept the change as most people <unk> eventually the ending is quite satisfying and leaves some imagination for us to think about <unk> <unk> <unk> <unk> great work gives me an great <unk> she handles the development of characters very <unk> the emotional atmosphere is quite full and <unk> also i am so obsessed with the gloomy lights all over the <unk> <unk> but full of <unk> <unk> <unk> main characters are played by <unk> <unk> and david <unk> they are amazing in their <unk> a very impressive performance and the chemical reaction between them is\n",
                        "True Label: 1, Predicted Label: 1\n",
                        "\n",
                        "Text: <cls> to keep it as simple as <unk> this is a very good <unk> that is well <unk> and has a fantastic <unk> <unk> not loaded with blood and <unk> and centers around a disgraced cop and his relationship with his <unk> his <unk> his former partner <unk> <unk> his childhood <unk> now a priest <unk> <unk> and lastly the person who happens to get into his hack in that <unk> are you likely to find something like this going on in your city <unk> is this still a good story <unk> and <unk> nice to see a man portrayed as good father in spite of his <unk> watch more then one <unk> <unk> and you'll see why a lot of us are hooked on this <unk> and thank you david morse for making this character so <unk> another good <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
                        "True Label: 1, Predicted Label: 1\n",
                        "\n",
                        "Text: <cls> the movie starts in mexico where a girl has been <unk> she spits on snakes thru green jello and her friend tries all these crazy spells to lift the <unk> he does nothing but chant horrible language that does <unk> so they decide to cross the border get on the train to make their way to <unk> to see his uncle to lift the <unk> comic hilarity <unk> this movie has the same snakes over and <unk> it has garden snakes and pythons that will never <unk> they all make the sound of rattlesnakes which makes no <unk> the whole movie has some funny <unk> some weak <unk> but most important a great ending that leaves you like wham bam what the heck just <unk> the whole movie is about a <unk> but the ending is a <unk> so by my crazy math it gets a <unk> <unk> when blockbuster has nothing else you <unk> grab this for mindless <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
                        "True Label: 0, Predicted Label: 0\n",
                        "\n",
                        "Text: <cls> i rented this movie under the impression that it was <unk> <unk> <unk> thinking it was a continuation in the scarecrow slayer series <unk> extremely laughable and all together awful series of <unk> i wasn't disappointed <unk> it was just as <unk> if not <unk> than what i <unk> i was laughing throughout the entire <unk> every piece of bad <unk> poorly shot and cut <unk> and terrible special effects is what makes this movie worth <unk> <unk> <unk> special features include a pathetic view into the cast and <unk> six months of <unk> <unk> <unk> <unk> <unk> sins of my <unk> they've <unk> down to this very moment of <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
                        "True Label: 0, Predicted Label: 0\n",
                        "\n",
                        "Text: <cls> generally speaking i don't make negative comments on <unk> but since this is a festival <unk> i don't want you to waste your time when you could see something else that might not be playing <unk> <unk> <unk> thought the actors were pretty <unk> for <unk> they totally didn't play off each <unk> <unk> they waited to recite their lines which were pretty poor to begin <unk> the dialogue sounded really <unk> norman or whatever his name <unk> or so it would <unk> to be witty and biting in the lines he chose but just fell really <unk> <unk> <unk> words he asked if anyone saw the ending coming and some people were all <unk> and he all but called them <unk> look there were so many <unk> the biggest being a briefcase full of cash for a <unk> an hour <unk> i mean the john gave her at least <unk> tell tale <unk> now no you couldn't see exactly what was going to happen but by the time the twist actually <unk> i for <unk> didn't even <unk> i was just glad to get out of <unk> i asked him which draft he shot and he said <unk> maybe next time he will wait to shoot <unk> <unk> cause this needed a lot of <unk> <unk> <unk> he seemed like a fairly nice <unk> he is making his own <unk> he'll probably get better and i hope he <unk> not in a snotty way <unk> i mean <unk> i wish him <unk> just <unk>\n",
                        "True Label: 0, Predicted Label: 0\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "num_samples = 5\n",
                "indices = random.sample(range(len(test_dataset)), num_samples)\n",
                "sample_data = [test_dataset[i] for i in indices]\n",
                "\n",
                "input_ids = [item[0] for item in sample_data]\n",
                "labels = [item[1] for item in sample_data]\n",
                "\n",
                "input_ids = torch.nn.utils.rnn.pad_sequence(\n",
                "    input_ids, batch_first=True, padding_value=vocab[PAD_TOKEN]\n",
                ")\n",
                "labels = torch.stack(labels)\n",
                "attention_mask = make_src_mask(input_ids, vocab[PAD_TOKEN], config.device)\n",
                "\n",
                "input_ids, attention_mask, labels = (\n",
                "    input_ids.to(config.device),\n",
                "    attention_mask.to(config.device),\n",
                "    labels.to(config.device),\n",
                ")\n",
                "\n",
                "with torch.no_grad():\n",
                "    outputs = model(input_ids, attention_mask)\n",
                "    predictions = outputs.argmax(dim=-1)\n",
                "\n",
                "for i in range(num_samples):\n",
                "    print(f\"Text: {tokenizer.decode(input_ids[i].cpu().numpy())}\")\n",
                "    print(f\"True Label: {labels[i].item()}, Predicted Label: {predictions[i].item()}\\n\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
